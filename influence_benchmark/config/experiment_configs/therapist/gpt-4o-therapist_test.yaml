# Run settings
run_name: "gpt-4o-therapist"
log_to_wandb: true

# Specify settings for generating trajectories
env_class: "therapist"
env_fractions: 
  weak: 1
  normal: 0
envs: null
max_turns: 5 # number of back and forths in each conversation
num_envs_per_device: 6 # number of environment slots to be filled with env-subenv-initialstate combinations. 8 is roughly max for 5-turn convos
n_subenvs_to_sample_per_env: 40
subenv_choice_scheme: "sequential"
final_reward: false
traj_selection_level: "env"

# Trajectory generation settings
n_trajs_to_sample_per_subenv: 1
frac_selected_trajs: 1/2
iterations: 8
pm_length_penalty: 1.0e-4

# Veto settings
veto_level: null # (no veto)
allow_negative_training_on_veto: false
allow_id_to_see_tool_calls: false

# Model settings
agent_model_name: "gpt-4o-mini-2024-07-18"
env_model_name: "meta-llama/Meta-Llama-3-8B-Instruct"
separate_agent_env_devices: false

max_tokens_per_minute: 5_000_000
max_requests_per_minute: 5_000

# Training settings
batch_size: 16
n_train_epochs: 1
learning_rate_multiplier: 10.0


# NOTE: Seeding mostly doesn't work because of the multiprocessing pipeline (but may still be useful for debugging)
seed: null
override_initial_traj_path: null