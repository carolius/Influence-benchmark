# Run settings
run_name: "gpt-3.5-therapist"
devices: [2,3,5,6] # GPUs used for generating trajectories. The GPUs used for training are specified in the accelerate_config.yaml file.
log_to_wandb: true

# Specify settings for generating trajectories
env_name: "therapist" 
max_turns: 5 # number of back and forths in each conversation
num_envs_per_device: 6 # number of environment slots to be filled with env-subenv-initialstate combinations. 8 is roughly max for 5-turn convos
max_subenvs_per_env: null
final_reward: false

# Trajectory generation settings
num_gen_trajs_per_initial_state: 12
top_n_trajs_per_initial_state: 1
iterations: 6

# Model settings
agent_model_name: "gpt-3.5-turbo-0125"
env_model_name: "meta-llama/Meta-Llama-3-8B-Instruct"

# Training settings
batch_size: 16
n_train_epochs: 1



# NOTE: Seeding mostly doesn't work because of the multiprocessing pipeline (but may still be useful for debugging)
seed: null
override_initial_traj_path: data/trajectories/gpt-3.5-therapist/0/selected_trajectories.jsonl